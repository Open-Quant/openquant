---
import Layout from '../layouts/Layout.astro';
---
<Layout title="Performance â€¢ OpenQuant-rs">
  <section class="hero">
    <h1>Performance and Benchmarking</h1>
    <p class="muted">Performance is treated as a tracked contract: benchmark suites, baselines, and threshold checks are versioned in-repo.</p>
  </section>

  <h2>Benchmark Suites</h2>
  <div class="grid">
    <article class="card">
      <h3><code>perf_hotspots</code></h3>
      <p>Targets algorithmically heavy paths (including structural-break and bet-sizing hotspots).</p>
    </article>
    <article class="card">
      <h3><code>synthetic_ticker_pipeline</code></h3>
      <p>Measures realistic end-to-end throughput over synthetic market-like time series.</p>
    </article>
  </div>

  <h2>Artifacts</h2>
  <table>
    <thead>
      <tr>
        <th>Artifact</th>
        <th>Role</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code>benchmarks/baseline_benchmarks.json</code></td>
        <td>Stable regression baseline committed to git.</td>
      </tr>
      <tr>
        <td><code>benchmarks/latest_benchmarks.json</code></td>
        <td>Latest collected run snapshot.</td>
      </tr>
      <tr>
        <td><code>benchmarks/benchmark_manifest.json</code></td>
        <td>Benchmark ID allow-list used for deterministic checks.</td>
      </tr>
      <tr>
        <td><code>docs/benchmark_snapshot.md</code></td>
        <td>Human-readable benchmark report for releases.</td>
      </tr>
    </tbody>
  </table>

  <h2>Recommended Protocol</h2>
  <ol>
    <li>Run benches on a consistent machine profile and avoid concurrent heavy workloads.</li>
    <li>Collect JSON output and compare against committed baseline.</li>
    <li>Investigate regressions before baseline updates.</li>
    <li>Only update baseline when behavior/perf changes are intended.</li>
  </ol>

  <pre><code class="language-bash">cargo bench -p openquant --bench perf_hotspots --bench synthetic_ticker_pipeline
python3 scripts/collect_bench_results.py --criterion-dir target/criterion --out benchmarks/latest_benchmarks.json --allow-list benchmarks/benchmark_manifest.json
python3 scripts/check_bench_thresholds.py --baseline benchmarks/baseline_benchmarks.json --latest benchmarks/latest_benchmarks.json --max-regression-pct 25</code></pre>

  <h2>CI Gate</h2>
  <p>The workflow <code>.github/workflows/benchmark-regression.yml</code> enforces configured regression thresholds on pull requests and mainline changes.</p>
</Layout>
